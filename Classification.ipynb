{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_tok=2</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so...</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drags'...</td>\n",
       "      <td>[('father', 'dysfunctional'), ('dysfunctional'...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks lyft credit  can not use cause  do not ...</td>\n",
       "      <td>['thanks', 'lyft', 'credit', 'can', 'not', 'us...</td>\n",
       "      <td>[('thanks', 'lyft'), ('lyft', 'credit'), ('cre...</td>\n",
       "      <td>['thank', 'lyft', 'credit', 'can', 'not', 'use...</td>\n",
       "      <td>thank lyft credit can not use cause do not off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>['bihday', 'majesty']</td>\n",
       "      <td>[('bihday', 'majesty')]</td>\n",
       "      <td>['bihday', 'majesty']</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>['factsguide', 'society', 'motivation']</td>\n",
       "      <td>[('factsguide', 'society'), ('society', 'motiv...</td>\n",
       "      <td>['factsguide', 'society', 'motivation']</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare big talking leave chaos pay disp...</td>\n",
       "      <td>['huge', 'fan', 'fare', 'big', 'talking', 'lea...</td>\n",
       "      <td>[('huge', 'fan'), ('fan', 'fare'), ('fare', 'b...</td>\n",
       "      <td>['huge', 'fan', 'fare', 'big', 'talk', 'leave'...</td>\n",
       "      <td>huge fan fare big talk leave chaos pay dispute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Toxicity                                              tweet  \\\n",
       "0         0  @user when a father is dysfunctional and is so...   \n",
       "1         0  @user @user thanks for #lyft credit i can't us...   \n",
       "2         0                                bihday your majesty   \n",
       "3         0             factsguide: society now    #motivation   \n",
       "4         0  [2/2] huge fan fare and big talking before the...   \n",
       "\n",
       "                                         tweet_clean  \\\n",
       "0  father dysfunctional selfish drags kids dysfun...   \n",
       "1  thanks lyft credit  can not use cause  do not ...   \n",
       "2                                     bihday majesty   \n",
       "3                      factsguide society motivation   \n",
       "4  huge fan fare big talking leave chaos pay disp...   \n",
       "\n",
       "                                     tweet_tokenized  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drags'...   \n",
       "1  ['thanks', 'lyft', 'credit', 'can', 'not', 'us...   \n",
       "2                              ['bihday', 'majesty']   \n",
       "3            ['factsguide', 'society', 'motivation']   \n",
       "4  ['huge', 'fan', 'fare', 'big', 'talking', 'lea...   \n",
       "\n",
       "                                         tweet_tok=2  \\\n",
       "0  [('father', 'dysfunctional'), ('dysfunctional'...   \n",
       "1  [('thanks', 'lyft'), ('lyft', 'credit'), ('cre...   \n",
       "2                            [('bihday', 'majesty')]   \n",
       "3  [('factsguide', 'society'), ('society', 'motiv...   \n",
       "4  [('huge', 'fan'), ('fan', 'fare'), ('fare', 'b...   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1  ['thank', 'lyft', 'credit', 'can', 'not', 'use...   \n",
       "2                              ['bihday', 'majesty']   \n",
       "3            ['factsguide', 'society', 'motivation']   \n",
       "4  ['huge', 'fan', 'fare', 'big', 'talk', 'leave'...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  father dysfunctional selfish drag kid dysfunct...  \n",
       "1  thank lyft credit can not use cause do not off...  \n",
       "2                                    bihday majesty   \n",
       "3                     factsguide society motivation   \n",
       "4  huge fan fare big talk leave chaos pay dispute...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"CleanDataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70% training e 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "X = df['preprocessed_text']\n",
    "y = df[\"Toxicity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=1000,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36523, 15653, 36523, 15653)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che restituisce un sunto delle metriche per valutare un modello di classificazione\n",
    "\n",
    "def model_evaluation(real_v, pred_v):\n",
    "    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(real_v, pred_v))\n",
    "    cm = confusion_matrix(real_v, pred_v)\n",
    "    print (f\"Confusion matrix \\n {cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Vectorization ---> Feature extraction\n",
    "- Fit to learn a vocabulary dictionary of all tokens in the raw documents\n",
    "- Transform documents to document-term matrix\n",
    "- Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5,ngram_range = (1,2))  # Convert a collection of text documents to a matrix of token counts.\n",
    "vect.fit(X_train)\n",
    "X_train_tok = vect.fit_transform(X_train)\n",
    "X_test_tok =vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "We apply the chi-square test to select the most important features.\n",
    "Chi2 measures the dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n",
    "\n",
    "To select the best K for the method: SelectKBest(chi2, k) we will test k=200, 300, 500, 800, 1000\n",
    "\n",
    "We utilize F1- because it the armonic mean between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione di una funzione per fare GridSearch sul k per la SelectKbest e sugli iperparametri dei vari classificatori utilizzati\n",
    "\n",
    "def GridSearch(X_train, X_test, y_train, y_test, metrics, model, params_to_check):\n",
    "\n",
    "    optimals = {}\n",
    "   \n",
    "    k_fold = StratifiedKFold(n_splits=3, random_state=42)\n",
    "    print(\"> Fold = \" + str(k_fold) + \"\\n\")\n",
    "        \n",
    "    clf = GridSearchCV(model, params_to_check, error_score='raise', cv=k_fold, scoring=\"f1_score\", return_train_score=True)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"> Best Parameter set: \\n\")\n",
    "    best = clf.best_params_\n",
    "    print(best)\n",
    "        \n",
    "    print(\"\\n> Grid scores:\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "        \n",
    "    print(\"...........RESULTS FOR TRAINING.........\")\n",
    "    print(\"........................................\")\n",
    "    means = clf.cv_results_['mean_train_score']\n",
    "    stds = clf.cv_results_['std_train_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print(\"........................................\")\n",
    "        \n",
    "    optimals[\"f1_score\"] = best\n",
    "    return optimals\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea8238db6dc1fe8cf6fe83219457bde9bcbcde2053d40c59d2e78211d10c5fee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

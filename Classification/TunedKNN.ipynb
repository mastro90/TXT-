{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, KFold, RandomizedSearchCV, RepeatedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_tok=2</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so...</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drags'...</td>\n",
       "      <td>[('father', 'dysfunctional'), ('dysfunctional'...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks lyft credit  can not use cause  do not ...</td>\n",
       "      <td>['thanks', 'lyft', 'credit', 'can', 'not', 'us...</td>\n",
       "      <td>[('thanks', 'lyft'), ('lyft', 'credit'), ('cre...</td>\n",
       "      <td>['thank', 'lyft', 'credit', 'can', 'not', 'use...</td>\n",
       "      <td>thank lyft credit can not use cause do not off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>['bihday', 'majesty']</td>\n",
       "      <td>[('bihday', 'majesty')]</td>\n",
       "      <td>['bihday', 'majesty']</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>['factsguide', 'society', 'motivation']</td>\n",
       "      <td>[('factsguide', 'society'), ('society', 'motiv...</td>\n",
       "      <td>['factsguide', 'society', 'motivation']</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare big talking leave chaos pay disp...</td>\n",
       "      <td>['huge', 'fan', 'fare', 'big', 'talking', 'lea...</td>\n",
       "      <td>[('huge', 'fan'), ('fan', 'fare'), ('fare', 'b...</td>\n",
       "      <td>['huge', 'fan', 'fare', 'big', 'talk', 'leave'...</td>\n",
       "      <td>huge fan fare big talk leave chaos pay dispute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Toxicity                                              tweet  \\\n",
       "0           0         0  @user when a father is dysfunctional and is so...   \n",
       "1           1         0  @user @user thanks for #lyft credit i can't us...   \n",
       "2           2         0                                bihday your majesty   \n",
       "3           4         0             factsguide: society now    #motivation   \n",
       "4           5         0  [2/2] huge fan fare and big talking before the...   \n",
       "\n",
       "                                         tweet_clean  \\\n",
       "0  father dysfunctional selfish drags kids dysfun...   \n",
       "1  thanks lyft credit  can not use cause  do not ...   \n",
       "2                                     bihday majesty   \n",
       "3                      factsguide society motivation   \n",
       "4  huge fan fare big talking leave chaos pay disp...   \n",
       "\n",
       "                                     tweet_tokenized  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drags'...   \n",
       "1  ['thanks', 'lyft', 'credit', 'can', 'not', 'us...   \n",
       "2                              ['bihday', 'majesty']   \n",
       "3            ['factsguide', 'society', 'motivation']   \n",
       "4  ['huge', 'fan', 'fare', 'big', 'talking', 'lea...   \n",
       "\n",
       "                                         tweet_tok=2  \\\n",
       "0  [('father', 'dysfunctional'), ('dysfunctional'...   \n",
       "1  [('thanks', 'lyft'), ('lyft', 'credit'), ('cre...   \n",
       "2                            [('bihday', 'majesty')]   \n",
       "3  [('factsguide', 'society'), ('society', 'motiv...   \n",
       "4  [('huge', 'fan'), ('fan', 'fare'), ('fare', 'b...   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1  ['thank', 'lyft', 'credit', 'can', 'not', 'use...   \n",
       "2                              ['bihday', 'majesty']   \n",
       "3            ['factsguide', 'society', 'motivation']   \n",
       "4  ['huge', 'fan', 'fare', 'big', 'talk', 'leave'...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  father dysfunctional selfish drag kid dysfunct...  \n",
       "1  thank lyft credit can not use cause do not off...  \n",
       "2                                    bihday majesty   \n",
       "3                     factsguide society motivation   \n",
       "4  huge fan fare big talk leave chaos pay dispute...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"CleanDataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['preprocessed_text']\n",
    "y = df[\"Toxicity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5,ngram_range = (1,2))  # Convert a collection of text documents to a matrix of token counts.\n",
    "vect.fit(X_train)\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec =vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_evaluation(real_v, pred_v):\n",
    "    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(real_v, pred_v))\n",
    "    cm = confusion_matrix(real_v, pred_v)\n",
    "    print (f\"Confusion matrix \\n {cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customRandomSearch(X_train, y_train, model, tuned_parameters):\n",
    "\n",
    "    print(\"____________________________________________ START GRID SEARCH ____________________________________________\")\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    print(\"------- Score = F1_MACRO ------- \\n\")\n",
    "        \n",
    "    k_fold = KFold(n_splits=5)\n",
    "    print(\"> Fold = \" + str(k_fold) + \"\\n\")\n",
    "\n",
    "\n",
    "    clf = RandomizedSearchCV(model, tuned_parameters, error_score='raise', cv=k_fold, scoring = 'f1_macro', return_train_score=True,n_jobs=-1,n_iter=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"> Best Parameter set: \\n\")\n",
    "    best = clf.best_params_\n",
    "    print(best)\n",
    "        \n",
    "    print(\"\\n> Grid scores:\\n\")\n",
    "\n",
    "    means = clf.cv_results_['mean_train_score']\n",
    "    stds = clf.cv_results_['std_train_score']\n",
    "\n",
    "    print(\"...........RESULTS FOR TRAINING.........\")\n",
    "    print(\"........................................\")\n",
    "\n",
    "   \n",
    "    \n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "                          \n",
    "    print(\"____________________________________________ END GRID SEARCH ____________________________________________\")\n",
    "        \n",
    "    results['f1_macro'] = best\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customGridSearch(X_train, y_train, model, tuned_parameters):\n",
    "\n",
    "    print(\"____________________________________________ START GRID SEARCH ____________________________________________\")\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    print(\"------- Score = F1_MACRO ------- \\n\")\n",
    "        \n",
    "    k_fold = KFold(n_splits=5)\n",
    "    print(\"> Fold = \" + str(k_fold) + \"\\n\")\n",
    "        \n",
    "    clf = GridSearchCV(model, tuned_parameters, error_score='raise', cv=k_fold, scoring = 'f1_macro',n_josb=-1,return_train_score=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"> Best Parameter set: \\n\")\n",
    "    best = clf.best_params_\n",
    "    print(best)\n",
    "        \n",
    "    print(\"\\n> Grid scores:\\n\")\n",
    "\n",
    "    means = clf.cv_results_['mean_train_score']\n",
    "    stds = clf.cv_results_['std_train_score']\n",
    "\n",
    "    print(\"...........RESULTS FOR TRAINING.........\")\n",
    "    print(\"........................................\")\n",
    "\n",
    "   \n",
    "    \n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "                          \n",
    "    print(\"____________________________________________ END GRID SEARCH ____________________________________________\")\n",
    "        \n",
    "    results['f1_macro'] = best\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________ START GRID SEARCH ____________________________________________\n",
      "------- Score = F1_MACRO ------- \n",
      "\n",
      "> Fold = KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n",
      " Start combinations\n",
      " Finish combinations\n",
      "> Best Parameter set: \n",
      "\n",
      "{'selbestk__k': 200, 'knn__n_neighbors': 7, 'knn__metric': 'manhattan'}\n",
      "\n",
      "> Grid scores:\n",
      "\n",
      "...........RESULTS FOR TRAINING.........\n",
      "........................................\n",
      "0.892 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 27, 'knn__metric': 'manhattan'}\n",
      "0.820 (+/-0.006) for {'selbestk__k': 1000, 'knn__n_neighbors': 21, 'knn__metric': 'euclidean'}\n",
      "0.856 (+/-0.006) for {'selbestk__k': 800, 'knn__n_neighbors': 17, 'knn__metric': 'euclidean'}\n",
      "0.909 (+/-0.005) for {'selbestk__k': 300, 'knn__n_neighbors': 5, 'knn__metric': 'euclidean'}\n",
      "0.907 (+/-0.007) for {'selbestk__k': 500, 'knn__n_neighbors': 5, 'knn__metric': 'manhattan'}\n",
      "0.896 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 15, 'knn__metric': 'manhattan'}\n",
      "0.898 (+/-0.005) for {'selbestk__k': 200, 'knn__n_neighbors': 17, 'knn__metric': 'manhattan'}\n",
      "0.847 (+/-0.008) for {'selbestk__k': 500, 'knn__n_neighbors': 25, 'knn__metric': 'manhattan'}\n",
      "0.887 (+/-0.002) for {'selbestk__k': 1000, 'knn__n_neighbors': 7, 'knn__metric': 'euclidean'}\n",
      "0.785 (+/-0.008) for {'selbestk__k': 800, 'knn__n_neighbors': 27, 'knn__metric': 'manhattan'}\n",
      "0.786 (+/-0.005) for {'selbestk__k': 1000, 'knn__n_neighbors': 21, 'knn__metric': 'manhattan'}\n",
      "0.791 (+/-0.006) for {'selbestk__k': 1000, 'knn__n_neighbors': 27, 'knn__metric': 'euclidean'}\n",
      "0.876 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 15, 'knn__metric': 'manhattan'}\n",
      "0.888 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 21, 'knn__metric': 'euclidean'}\n",
      "0.870 (+/-0.004) for {'selbestk__k': 500, 'knn__n_neighbors': 17, 'knn__metric': 'manhattan'}\n",
      "0.905 (+/-0.005) for {'selbestk__k': 200, 'knn__n_neighbors': 7, 'knn__metric': 'euclidean'}\n",
      "0.842 (+/-0.005) for {'selbestk__k': 800, 'knn__n_neighbors': 21, 'knn__metric': 'euclidean'}\n",
      "0.893 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 25, 'knn__metric': 'manhattan'}\n",
      "0.827 (+/-0.006) for {'selbestk__k': 800, 'knn__n_neighbors': 19, 'knn__metric': 'manhattan'}\n",
      "0.884 (+/-0.037) for {'selbestk__k': 800, 'knn__n_neighbors': 7, 'knn__metric': 'euclidean'}\n",
      "0.900 (+/-0.006) for {'selbestk__k': 200, 'knn__n_neighbors': 13, 'knn__metric': 'manhattan'}\n",
      "0.813 (+/-0.005) for {'selbestk__k': 1000, 'knn__n_neighbors': 17, 'knn__metric': 'manhattan'}\n",
      "0.887 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 23, 'knn__metric': 'euclidean'}\n",
      "0.899 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 7, 'knn__metric': 'euclidean'}\n",
      "0.904 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 9, 'knn__metric': 'manhattan'}\n",
      "0.859 (+/-0.005) for {'selbestk__k': 800, 'knn__n_neighbors': 13, 'knn__metric': 'manhattan'}\n",
      "0.761 (+/-0.005) for {'selbestk__k': 1000, 'knn__n_neighbors': 25, 'knn__metric': 'manhattan'}\n",
      "0.882 (+/-0.004) for {'selbestk__k': 500, 'knn__n_neighbors': 13, 'knn__metric': 'manhattan'}\n",
      "0.891 (+/-0.002) for {'selbestk__k': 300, 'knn__n_neighbors': 19, 'knn__metric': 'manhattan'}\n",
      "0.894 (+/-0.038) for {'selbestk__k': 800, 'knn__n_neighbors': 5, 'knn__metric': 'euclidean'}\n",
      "0.816 (+/-0.006) for {'selbestk__k': 800, 'knn__n_neighbors': 21, 'knn__metric': 'manhattan'}\n",
      "0.849 (+/-0.005) for {'selbestk__k': 800, 'knn__n_neighbors': 19, 'knn__metric': 'euclidean'}\n",
      "0.910 (+/-0.007) for {'selbestk__k': 300, 'knn__n_neighbors': 5, 'knn__metric': 'manhattan'}\n",
      "0.895 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 19, 'knn__metric': 'euclidean'}\n",
      "0.801 (+/-0.007) for {'selbestk__k': 1000, 'knn__n_neighbors': 25, 'knn__metric': 'euclidean'}\n",
      "0.901 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 7, 'knn__metric': 'manhattan'}\n",
      "0.906 (+/-0.006) for {'selbestk__k': 200, 'knn__n_neighbors': 7, 'knn__metric': 'manhattan'}\n",
      "0.838 (+/-0.006) for {'selbestk__k': 800, 'knn__n_neighbors': 17, 'knn__metric': 'manhattan'}\n",
      "0.905 (+/-0.006) for {'selbestk__k': 300, 'knn__n_neighbors': 7, 'knn__metric': 'manhattan'}\n",
      "0.897 (+/-0.005) for {'selbestk__k': 200, 'knn__n_neighbors': 19, 'knn__metric': 'manhattan'}\n",
      "0.899 (+/-0.006) for {'selbestk__k': 200, 'knn__n_neighbors': 15, 'knn__metric': 'manhattan'}\n",
      "0.882 (+/-0.004) for {'selbestk__k': 300, 'knn__n_neighbors': 27, 'knn__metric': 'manhattan'}\n",
      "0.906 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 5, 'knn__metric': 'euclidean'}\n",
      "0.901 (+/-0.006) for {'selbestk__k': 200, 'knn__n_neighbors': 11, 'knn__metric': 'manhattan'}\n",
      "0.848 (+/-0.005) for {'selbestk__k': 800, 'knn__n_neighbors': 15, 'knn__metric': 'manhattan'}\n",
      "0.904 (+/-0.005) for {'selbestk__k': 800, 'knn__n_neighbors': 5, 'knn__metric': 'manhattan'}\n",
      "0.876 (+/-0.003) for {'selbestk__k': 1000, 'knn__n_neighbors': 9, 'knn__metric': 'euclidean'}\n",
      "0.901 (+/-0.003) for {'selbestk__k': 200, 'knn__n_neighbors': 11, 'knn__metric': 'euclidean'}\n",
      "0.867 (+/-0.003) for {'selbestk__k': 1000, 'knn__n_neighbors': 11, 'knn__metric': 'euclidean'}\n",
      "0.900 (+/-0.002) for {'selbestk__k': 1000, 'knn__n_neighbors': 5, 'knn__metric': 'euclidean'}\n",
      "0.899 (+/-0.005) for {'selbestk__k': 200, 'knn__n_neighbors': 13, 'knn__metric': 'euclidean'}\n",
      "0.869 (+/-0.004) for {'selbestk__k': 800, 'knn__n_neighbors': 13, 'knn__metric': 'euclidean'}\n",
      "0.869 (+/-0.004) for {'selbestk__k': 800, 'knn__n_neighbors': 11, 'knn__metric': 'manhattan'}\n",
      "0.888 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 11, 'knn__metric': 'manhattan'}\n",
      "0.865 (+/-0.006) for {'selbestk__k': 500, 'knn__n_neighbors': 19, 'knn__metric': 'manhattan'}\n",
      "0.892 (+/-0.003) for {'selbestk__k': 200, 'knn__n_neighbors': 25, 'knn__metric': 'euclidean'}\n",
      "0.895 (+/-0.006) for {'selbestk__k': 300, 'knn__n_neighbors': 13, 'knn__metric': 'euclidean'}\n",
      "0.826 (+/-0.003) for {'selbestk__k': 1000, 'knn__n_neighbors': 15, 'knn__metric': 'manhattan'}\n",
      "0.880 (+/-0.004) for {'selbestk__k': 800, 'knn__n_neighbors': 9, 'knn__metric': 'manhattan'}\n",
      "0.861 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 25, 'knn__metric': 'euclidean'}\n",
      "0.883 (+/-0.004) for {'selbestk__k': 300, 'knn__n_neighbors': 27, 'knn__metric': 'euclidean'}\n",
      "0.840 (+/-0.003) for {'selbestk__k': 1000, 'knn__n_neighbors': 13, 'knn__metric': 'manhattan'}\n",
      "0.883 (+/-0.006) for {'selbestk__k': 500, 'knn__n_neighbors': 13, 'knn__metric': 'euclidean'}\n",
      "0.876 (+/-0.002) for {'selbestk__k': 800, 'knn__n_neighbors': 11, 'knn__metric': 'euclidean'}\n",
      "0.909 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 5, 'knn__metric': 'euclidean'}\n",
      "0.894 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 23, 'knn__metric': 'manhattan'}\n",
      "0.879 (+/-0.004) for {'selbestk__k': 500, 'knn__n_neighbors': 15, 'knn__metric': 'euclidean'}\n",
      "0.811 (+/-0.006) for {'selbestk__k': 1000, 'knn__n_neighbors': 23, 'knn__metric': 'euclidean'}\n",
      "0.897 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 15, 'knn__metric': 'euclidean'}\n",
      "0.884 (+/-0.003) for {'selbestk__k': 800, 'knn__n_neighbors': 9, 'knn__metric': 'euclidean'}\n",
      "0.841 (+/-0.008) for {'selbestk__k': 500, 'knn__n_neighbors': 27, 'knn__metric': 'manhattan'}\n",
      "0.898 (+/-0.002) for {'selbestk__k': 300, 'knn__n_neighbors': 13, 'knn__metric': 'manhattan'}\n",
      "0.875 (+/-0.004) for {'selbestk__k': 500, 'knn__n_neighbors': 17, 'knn__metric': 'euclidean'}\n",
      "0.827 (+/-0.007) for {'selbestk__k': 800, 'knn__n_neighbors': 25, 'knn__metric': 'euclidean'}\n",
      "0.799 (+/-0.004) for {'selbestk__k': 1000, 'knn__n_neighbors': 19, 'knn__metric': 'manhattan'}\n",
      "0.835 (+/-0.007) for {'selbestk__k': 800, 'knn__n_neighbors': 23, 'knn__metric': 'euclidean'}\n",
      "0.852 (+/-0.007) for {'selbestk__k': 500, 'knn__n_neighbors': 23, 'knn__metric': 'manhattan'}\n",
      "0.795 (+/-0.007) for {'selbestk__k': 800, 'knn__n_neighbors': 25, 'knn__metric': 'manhattan'}\n",
      "0.887 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 23, 'knn__metric': 'manhattan'}\n",
      "0.894 (+/-0.006) for {'selbestk__k': 500, 'knn__n_neighbors': 9, 'knn__metric': 'manhattan'}\n",
      "0.902 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 9, 'knn__metric': 'euclidean'}\n",
      "0.893 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 17, 'knn__metric': 'manhattan'}\n",
      "0.898 (+/-0.003) for {'selbestk__k': 1000, 'knn__n_neighbors': 5, 'knn__metric': 'manhattan'}\n",
      "0.905 (+/-0.005) for {'selbestk__k': 300, 'knn__n_neighbors': 7, 'knn__metric': 'euclidean'}\n",
      "0.830 (+/-0.005) for {'selbestk__k': 1000, 'knn__n_neighbors': 19, 'knn__metric': 'euclidean'}\n",
      "0.858 (+/-0.007) for {'selbestk__k': 500, 'knn__n_neighbors': 27, 'knn__metric': 'euclidean'}\n",
      "0.772 (+/-0.005) for {'selbestk__k': 1000, 'knn__n_neighbors': 23, 'knn__metric': 'manhattan'}\n",
      "0.859 (+/-0.007) for {'selbestk__k': 500, 'knn__n_neighbors': 21, 'knn__metric': 'manhattan'}\n",
      "0.888 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 11, 'knn__metric': 'euclidean'}\n",
      "0.891 (+/-0.003) for {'selbestk__k': 200, 'knn__n_neighbors': 27, 'knn__metric': 'euclidean'}\n",
      "0.872 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 19, 'knn__metric': 'euclidean'}\n",
      "0.849 (+/-0.006) for {'selbestk__k': 1000, 'knn__n_neighbors': 15, 'knn__metric': 'euclidean'}\n",
      "0.894 (+/-0.003) for {'selbestk__k': 200, 'knn__n_neighbors': 21, 'knn__metric': 'euclidean'}\n",
      "0.892 (+/-0.004) for {'selbestk__k': 300, 'knn__n_neighbors': 17, 'knn__metric': 'euclidean'}\n",
      "0.889 (+/-0.003) for {'selbestk__k': 300, 'knn__n_neighbors': 21, 'knn__metric': 'manhattan'}\n",
      "0.750 (+/-0.004) for {'selbestk__k': 1000, 'knn__n_neighbors': 27, 'knn__metric': 'manhattan'}\n",
      "0.892 (+/-0.005) for {'selbestk__k': 800, 'knn__n_neighbors': 7, 'knn__metric': 'manhattan'}\n",
      "0.805 (+/-0.007) for {'selbestk__k': 800, 'knn__n_neighbors': 23, 'knn__metric': 'manhattan'}\n",
      "0.897 (+/-0.004) for {'selbestk__k': 200, 'knn__n_neighbors': 17, 'knn__metric': 'euclidean'}\n",
      "0.868 (+/-0.005) for {'selbestk__k': 500, 'knn__n_neighbors': 21, 'knn__metric': 'euclidean'}\n",
      "____________________________________________ END GRID SEARCH ____________________________________________\n"
     ]
    }
   ],
   "source": [
    "check_params = {\"selbestk__k\": [200, 300, 500, 800, 1000],\n",
    "          'knn__n_neighbors': list(range(5,28,2)),\n",
    "          #'knn__weights': ['uniform', 'distance'],\n",
    "          'knn__metric': [\"euclidean\", \"manhattan\"]}\n",
    "\n",
    "clf = Pipeline([\n",
    "                (\"selbestk\", SelectKBest(score_func = chi2)),\n",
    "                (\"tfidf\", TfidfTransformer()),\n",
    "                (\"knn\", KNeighborsClassifier())\n",
    "                ])\n",
    "\n",
    "results = customRandomSearch(X_train_vec, y_train , clf, check_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=200)  \n",
    "sel.fit(X_train_vec,y_train)\n",
    "X_train_sel = sel.transform(X_train_vec)\n",
    "X_test_sel = sel.transform(X_test_vec)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(X_train_sel)\n",
    "X_train_vec_bestK = tfidf.transform(X_train_sel)\n",
    "X_test_vec_bestK =tfidf.transform(X_test_sel)\n",
    "\n",
    "learner = KNeighborsClassifier(n_neighbors = 7, metric = 'manhattan')\n",
    "classifier = learner.fit(X_train_vec_bestK, y_train)\n",
    "predictions = classifier.predict(X_test_vec_bestK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.8964415766945634\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      8713\n",
      "           1       0.93      0.82      0.88      6940\n",
      "\n",
      "    accuracy                           0.90     15653\n",
      "   macro avg       0.90      0.89      0.89     15653\n",
      "weighted avg       0.90      0.90      0.90     15653\n",
      "\n",
      "Confusion matrix \n",
      " [[8308  405]\n",
      " [1216 5724]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
